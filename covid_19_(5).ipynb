{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucioJuniorMachado/Trabalho_Redes_Neurais/blob/main/covid_19_(5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F8w7HkwdVvR"
      },
      "source": [
        "#Vamos Classificar RX de covid e normais"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "FJOK5ZgO37SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20"
      ],
      "metadata": {
        "id": "dD1EH9fhgqXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVUTid9Hoya4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from imutils import paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KznG8EtbdR_B"
      },
      "source": [
        "Vamos a procurar o caminho de nossa base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHnPvkb4iVJC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "workdir_path = '/content/drive/My Drive/dataset-20250408T150050Z-001'  # Inserir o local da pasta onde estão os arquivos de entrada (treino e teste)\n",
        "os.chdir(workdir_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5191Nk-gfA2"
      },
      "source": [
        "#Vamos colocar os parametros de nosso modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZySzLQiroya9"
      },
      "outputs": [],
      "source": [
        "INIT_LR = 1e-3\n",
        "EPOCHS = 15 # PODE MUDAR\n",
        "BS = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_RzsgBDgjtt"
      },
      "source": [
        "# toma la lista de imágenes en nuestro directorio de conjuntos de datos, luego inicializa\n",
        "# la lista de datos (es decir, imágenes) e imágenes de clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tYcZnsLoybA"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_path = 'dataset'\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(dataset_path))\n",
        "data = []\n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xwTCniloybG"
      },
      "outputs": [],
      "source": [
        "# recorrer las rutas de la imagen\n",
        "for imagePath in imagePaths:\n",
        "    # extrae la etiqueta de clase del nombre del archivo\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "   # cargue la imagen, intercambie canales de color y cambie su tamaño para que sea una\n",
        "   # 224x224 píxeles sin tener en cuenta la relación de aspecto\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # actualizar las listas de datos y etiquetas, respectivamente\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "print(\"labels: \", np.unique(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeZ1cenJoybK"
      },
      "outputs": [],
      "source": [
        "# convierta los datos y las etiquetas en matrices NumPy mientras escala el píxel\n",
        "# intensidades en el rango [0, 255]\n",
        "data = np.array(data) / 255.0\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly4e1H7-oybQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(data[labels=='covid'][1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCaXg11doybU"
      },
      "outputs": [],
      "source": [
        "# realizar una codificación one-hot en las etiquetas\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5i7qoOeoybY"
      },
      "outputs": [],
      "source": [
        "# particione los datos en divisiones de entrenamiento y prueba usando el 80% de\n",
        "# los datos para entrenamiento y el 20% restante para pruebas\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "                                                  test_size=0.20, stratify=labels, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC2SRYPxiAr4"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW3HO7wGoybb"
      },
      "outputs": [],
      "source": [
        "# initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkjoE4Gloybf"
      },
      "outputs": [],
      "source": [
        "# cargue la red VGG16, asegurándose de que queden los conjuntos de capas FC principales\n",
        "# off\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "                  input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "#headModel = MaxPooling2D(pool_size=(2, 2))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.3)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)  # Replace 'decay' with 'learning_rate'\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D66VDVBoybk"
      },
      "outputs": [],
      "source": [
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "                  input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "f1 = baseModel.layers[1].output\n",
        "f2 = baseModel.layers[2].output\n",
        "f3 = baseModel.layers[4].output\n",
        "f4 = baseModel.layers[5].output\n",
        "feature_maps = Model(inputs=baseModel.input, outputs=[f1, f2, f3, f4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAhBtZWAoybo"
      },
      "outputs": [],
      "source": [
        "y = np.argmax(trainY, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VlCF3zooybr"
      },
      "outputs": [],
      "source": [
        "feat1, feat2, feat3, feat4 = feature_maps.predict(trainX[y==1][0:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qN7RgDAoybv"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axs[0, 0].imshow(feat1[0, :, :, 0:3])\n",
        "axs[0, 1].imshow(feat2[0, :, :, 6:9])\n",
        "axs[1, 0].imshow(feat3[0, :, :, 0:3])\n",
        "axs[1, 1].imshow(feat4[0, :, :, 3:6])\n",
        "# plt.subplots\n",
        "# plt.imshow(feat1[0, :, :, 0:3])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucihTbbepcNZ"
      },
      "source": [
        "##passo os dados de entrada"
      ]
    },
    {
      "source": [
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "    trainAug.flow(trainX, trainY, batch_size=BS),\n",
        "    steps_per_epoch=len(trainX) // BS,\n",
        "    validation_data=(testX, testY),\n",
        "    validation_steps=len(testX) // BS,\n",
        "    epochs=EPOCHS)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sItDjW15ncA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59u6ch-boyb3"
      },
      "outputs": [],
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "                            target_names=lb.classes_))\n",
        "\n",
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "# plt.savefig(args[\"plot\"])\n",
        "\n",
        "# serialize the model to disk\n",
        "# print(\"[INFO] saving COVID-19 detector model...\")\n",
        "# model.save(args[\"model\"], save_format=\"h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementando o modelo vgg19"
      ],
      "metadata": {
        "id": "11MrJ7Tjj53t"
      }
    },
    {
      "source": [
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg19 import VGG19 # Import VGG19 model\n",
        "from tensorflow.keras.applications.vgg19 import decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import img_to_array # Assuming this was imported earlier\n",
        "from numpy import expand_dims # Assuming this was imported earlier\n",
        "import cv2 # Assuming this was imported earlier\n",
        "\n",
        "\n",
        "# The 'image' variable is already a NumPy array from previous steps.\n",
        "# If you intend to process a *new* image, you would load it here.\n",
        "# For demonstration, let's assume 'image' is the NumPy array you want to use.\n",
        "\n",
        "# If the image is not already 224x224, resize it using cv2\n",
        "# Check if the image needs resizing (assuming HxWxC format)\n",
        "if image.shape[0] != 224 or image.shape[1] != 224:\n",
        "    # Resize the image using OpenCV\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "# The image is already a NumPy array, so img_to_array might not be necessary\n",
        "# depending on how 'image' was obtained. If 'image' is guaranteed to be a NumPy array\n",
        "# with the correct shape and dtype after resizing (if needed), this line might be redundant.\n",
        "# However, if 'image' was a PIL Image object *before* the error, and you want to\n",
        "# convert it to a NumPy array, this line would be correct *after* the PIL resize.\n",
        "# Since the error indicates 'image' is already a NumPy array, we'll assume it is.\n",
        "# If you were starting with a PIL Image, the workflow would be:\n",
        "# from PIL import Image\n",
        "# image_pil = Image.open(\"your_image.jpg\")\n",
        "# image_pil = image_pil.resize((224, 224))\n",
        "# image_array = img_to_array(image_pil)\n",
        "# Or more simply using cv2:\n",
        "# image_cv2 = cv2.imread(\"your_image.jpg\")\n",
        "# image_array = cv2.resize(image_cv2, (224, 224)) # cv2 reads as BGR, so need to convert if model expects RGB\n",
        "\n",
        "# Let's assume 'image' is the correctly sized (224, 224, 3) NumPy array in RGB format.\n",
        "\n",
        "# Expanda a dimensão para criar um batch de tamanho 1 (o modelo espera um batch)\n",
        "image_array = expand_dims(image, axis=0) # Use the existing 'image' array\n",
        "\n",
        "# Pré-processe a imagem para o VGG19\n",
        "# Isso subtrai a média dos canais VGG19 e garante a ordem correta dos canais (RGB para BGR se necessário)\n",
        "# Note: preprocess_input for VGG models typically converts RGB to BGR and subtracts mean.\n",
        "image_array_processed = preprocess_input(image_array)\n",
        "\n",
        "# Carregue o modelo VGG19 pré-treinado no ImageNet\n",
        "# Fix: Instantiate the VGG19 model correctly\n",
        "model_vgg19 = VGG19(weights=\"imagenet\", include_top=True)\n",
        "\n",
        "# Realize a inferência na imagem pré-processada\n",
        "predictions = model_vgg19.predict(image_array_processed)\n",
        "\n",
        "# O modelo VGG19 com include_top=True retorna probabilidades para as 1000 classes do ImageNet.\n",
        "# Para interpretar os resultados, podemos usar a função decode_predictions do Keras.\n",
        "\n",
        "# Decodifique as 3 principais previsões\n",
        "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "\n",
        "print(\"\\n--- Resultados da Inferência VGG19 ---\")\n",
        "for class_id, class_name, score in decoded_predictions:\n",
        "    print(f\"Classe: {class_name}, Probabilidade: {score:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Eo1SXschoBI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento da rede vgg19 com 20 épocas"
      ],
      "metadata": {
        "id": "1TxmHGQ3o6z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG19 network, ensuring the head FC layers are left off\n",
        "# Change VGG16 to VGG19\n",
        "baseModel = VGG19(weights=\"imagenet\", include_top=False,\n",
        "                  input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.3)(headModel)\n",
        "# Assuming binary classification (covid/normal), output layer has 2 units\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "# Use the optimizer defined previously\n",
        "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# Use binary_crossentropy for binary classification\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "# Change EPOCHS to 20\n",
        "EPOCHS = 20\n",
        "H = model.fit(\n",
        "    trainAug.flow(trainX, trainY, batch_size=BS),\n",
        "    steps_per_epoch=len(trainX) // BS,\n",
        "    validation_data=(testX, testY),\n",
        "    validation_steps=len(testX) // BS,\n",
        "    epochs=EPOCHS)\n",
        "\n",
        "# The code for evaluation and plotting already exists and will use the results from this training run.\n",
        "# No need to repeat the evaluation and plotting code."
      ],
      "metadata": {
        "id": "AN6AA5tFo3Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparação de acurácia e perda de validação entre as redes vgg16 e vgg19"
      ],
      "metadata": {
        "id": "w_DGv8uZpkMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Save the training history for VGG16\n",
        "history_vgg16 = H\n",
        "\n",
        "# Now, redefine and train the VGG19 model\n",
        "print(\"\\n[INFO] Training VGG19 model...\")\n",
        "\n",
        "# Load the VGG19 network, ensuring the head FC layers are left off\n",
        "baseModel_vgg19 = VGG19(weights=\"imagenet\", include_top=False,\n",
        "                        input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel_vgg19 = baseModel_vgg19.output\n",
        "headModel_vgg19 = Flatten(name=\"flatten_vgg19\")(headModel_vgg19)\n",
        "headModel_vgg19 = Dense(128, activation=\"relu\")(headModel_vgg19)\n",
        "headModel_vgg19 = Dropout(0.3)(headModel_vgg19)\n",
        "headModel_vgg19 = Dense(2, activation=\"softmax\")(headModel_vgg19)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model_vgg19 = Model(inputs=baseModel_vgg19.input, outputs=headModel_vgg19)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel_vgg19.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile our model\n",
        "print(\"[INFO] compiling VGG19 model...\")\n",
        "# Use the optimizer defined previously\n",
        "opt_vgg19 = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model_vgg19.compile(loss=\"binary_crossentropy\", optimizer=opt_vgg19,\n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the head of the network\n",
        "print(\"[INFO] training VGG19 head...\")\n",
        "# Use the same number of EPOCHS for fair comparison, or define a new one if needed\n",
        "EPOCHS_VGG19 = EPOCHS # Using the same EPOCHS value\n",
        "history_vgg19 = model_vgg19.fit(\n",
        "    trainAug.flow(trainX, trainY, batch_size=BS),\n",
        "    steps_per_epoch=len(trainX) // BS,\n",
        "    validation_data=(testX, testY),\n",
        "    validation_steps=len(testX) // BS,\n",
        "    epochs=EPOCHS_VGG19)\n",
        "\n",
        "# --- Compare and Plot Results ---\n",
        "\n",
        "# Plot training loss and accuracy for both models\n",
        "N_vgg16 = len(history_vgg16.history[\"loss\"])\n",
        "N_vgg19 = len(history_vgg19.history[\"loss\"])\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(np.arange(0, N_vgg16), history_vgg16.history[\"loss\"], label=\"VGG16 train_loss\")\n",
        "plt.plot(np.arange(0, N_vgg16), history_vgg16.history[\"val_loss\"], label=\"VGG16 val_loss\")\n",
        "plt.plot(np.arange(0, N_vgg19), history_vgg19.history[\"loss\"], label=\"VGG19 train_loss\")\n",
        "plt.plot(np.arange(0, N_vgg19), history_vgg19.history[\"val_loss\"], label=\"VGG19 val_loss\")\n",
        "plt.title(\"Training and Validation Loss Comparison\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "# Plot training accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.arange(0, N_vgg16), history_vgg16.history[\"accuracy\"], label=\"VGG16 train_acc\")\n",
        "plt.plot(np.arange(0, N_vgg16), history_vgg16.history[\"val_accuracy\"], label=\"VGG16 val_acc\")\n",
        "plt.plot(np.arange(0, N_vgg19), history_vgg19.history[\"accuracy\"], label=\"VGG19 train_acc\")\n",
        "plt.plot(np.arange(0, N_vgg19), history_vgg19.history[\"val_accuracy\"], label=\"VGG19 val_acc\")\n",
        "plt.title(\"Training and Validation Accuracy Comparison\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate VGG19 model and print classification report and confusion matrix\n",
        "print(\"\\n[INFO] Evaluating VGG19 network...\")\n",
        "predIdxs_vgg19 = model_vgg19.predict(testX, batch_size=BS)\n",
        "predIdxs_vgg19 = np.argmax(predIdxs_vgg19, axis=1)\n",
        "\n",
        "print(\"\\n--- Classification Report VGG19 ---\")\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs_vgg19,\n",
        "                            target_names=lb.classes_))\n",
        "\n",
        "cm_vgg19 = confusion_matrix(testY.argmax(axis=1), predIdxs_vgg19)\n",
        "total_vgg19 = sum(sum(cm_vgg19))\n",
        "acc_vgg19 = (cm_vgg19[0, 0] + cm_vgg19[1, 1]) / total_vgg19\n",
        "\n",
        "print(\"\\n--- Confusion Matrix VGG19 ---\")\n",
        "print(cm_vgg19)\n",
        "print(\"VGG19 acc: {:.4f}\".format(acc_vgg19))\n"
      ],
      "metadata": {
        "id": "LBYfJiyQpTfU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}