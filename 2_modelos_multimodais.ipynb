{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBAL45m0+x4ehD510vZr3E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucioJuniorMachado/Trabalho_Redes_Neurais/blob/main/2_modelos_multimodais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Zero-shot object detection**"
      ],
      "metadata": {
        "id": "3p_3NkNyYj3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando as bibliotecas necessárias"
      ],
      "metadata": {
        "id": "9zkebKg9TRO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "27zXWbKASot8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow\n",
        "!pip install matplotlib\n",
        "!pip install opencv-python\n",
        "import cv2\n",
        "import skimage\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from IPython.display import display # Import display if not already imported in the first cell"
      ],
      "metadata": {
        "id": "xWPO6IvBTd1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import send_example_telemetry\n",
        "\n",
        "send_example_telemetry(\"IDEA-Research/grounding-dino-base\", framework=\"pytorch\")"
      ],
      "metadata": {
        "id": "7h0VbnbATpk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando modelo pré-treinado e processador"
      ],
      "metadata": {
        "id": "wyCBOGEeUOCl"
      }
    },
    {
      "source": [
        "from transformers import AutoProcessor, OwlViTForObjectDetection, OwlViTProcessor\n",
        "\n",
        "# Increase the timeout for downloading the model files\n",
        "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\") #, request_timeout=60.0)\n",
        "\n",
        "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Y10lgHEVzeJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from transformers import AutoProcessor, OwlViTForObjectDetection, OwlViTProcessor\n",
        "\n",
        "# Increase the timeout for downloading the model files\n",
        "# Explicitly specify the revision to try and resolve potential issues with the latest version\n",
        "# Remove request_timeout and revision as they are not parameters for the model's __init__\n",
        "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")\n",
        "\n",
        "# The processor also doesn't need these arguments for its __init__\n",
        "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9MEWon-_90Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazendo o download da imagem"
      ],
      "metadata": {
        "id": "boebgDBiU7v0"
      }
    },
    {
      "source": [
        "url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRVnXoO798Cv_gfLX_zxvO3Lm4_CaK32J51NQ&s\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "image_array = skimage.io.imread(url)\n",
        "# Create a PIL Image object from the NumPy array\n",
        "im = Image.fromarray(image_array)\n",
        "# Use display to show the image in the notebook\n",
        "display(im)\n",
        "\n",
        "# Text queries to search the image for\n",
        "text_queries = [\"human face\", \"pipe\", \"chair\", \"books\"]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sbtq8cyBWULU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Use GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "hb-kYnKVU_rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Process image and text inputs\n",
        "inputs = processor(text=text_queries, images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Print input names and shapes\n",
        "for key, val in inputs.items():\n",
        "    print(f\"{key}: {val.shape}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "IMmlm5x2V-hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model in evaluation mode\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "for k, val in outputs.items():\n",
        "    if k not in {\"text_model_output\", \"vision_model_output\"}:\n",
        "        print(f\"{k}: shape of {val.shape}\")\n",
        "\n",
        "print(\"\\nText model outputs\")\n",
        "for k, val in outputs.text_model_output.items():\n",
        "    print(f\"{k}: shape of {val.shape}\")\n",
        "\n",
        "print(\"\\nVision model outputs\")\n",
        "for k, val in outputs.vision_model_output.items():\n",
        "    print(f\"{k}: shape of {val.shape}\")"
      ],
      "metadata": {
        "id": "F7fv613qW9j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detectando a imagem, desenhando sua predição"
      ],
      "metadata": {
        "id": "6nqsqTHEX77z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers.image_utils import ImageFeatureExtractionMixin\n",
        "mixin = ImageFeatureExtractionMixin()\n",
        "\n",
        "# Load example image\n",
        "image_size = model.config.vision_config.image_size\n",
        "image = mixin.resize(image, image_size)\n",
        "input_image = np.asarray(image).astype(np.float32) / 255.0\n",
        "\n",
        "# Threshold to eliminate low probability predictions\n",
        "score_threshold = 0.1\n",
        "\n",
        "# Get prediction logits\n",
        "logits = torch.max(outputs[\"logits\"][0], dim=-1)\n",
        "scores = torch.sigmoid(logits.values).cpu().detach().numpy()\n",
        "\n",
        "# Get prediction labels and boundary boxes\n",
        "labels = logits.indices.cpu().detach().numpy()\n",
        "boxes = outputs[\"pred_boxes\"][0].cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "8zSj_FR2Xu3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(input_image, text_queries, scores, boxes, labels):\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "    ax.imshow(input_image, extent=(0, 1, 1, 0))\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    for score, box, label in zip(scores, boxes, labels):\n",
        "      if score < score_threshold:\n",
        "        continue\n",
        "\n",
        "      cx, cy, w, h = box\n",
        "      ax.plot([cx-w/2, cx+w/2, cx+w/2, cx-w/2, cx-w/2],\n",
        "              [cy-h/2, cy-h/2, cy+h/2, cy+h/2, cy-h/2], \"r\")\n",
        "      ax.text(\n",
        "          cx - w / 2,\n",
        "          cy + h / 2 + 0.015,\n",
        "          f\"{text_queries[label]}: {score:1.2f}\",\n",
        "          ha=\"left\",\n",
        "          va=\"top\",\n",
        "          color=\"red\",\n",
        "          bbox={\n",
        "              \"facecolor\": \"white\",\n",
        "              \"edgecolor\": \"red\",\n",
        "              \"boxstyle\": \"square,pad=.3\"\n",
        "          })\n",
        "\n",
        "plot_predictions(input_image, text_queries, scores, boxes, labels)"
      ],
      "metadata": {
        "id": "7pa7qeCzX0o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Zero-shot classification para classificação de imagem em diferentes categorias**"
      ],
      "metadata": {
        "id": "fRDEksKJZ1Xc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando as bibliotecas"
      ],
      "metadata": {
        "id": "EA_6oNQktFRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q \"transformers[torch]\" pillow\n",
        "import cv2\n",
        "import skimage\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from IPython.display import display # Import display if not already imported in the first cell"
      ],
      "metadata": {
        "id": "qC--ws4vs3PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instanciando a pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "-_iTETjkaJ7H"
      }
    },
    {
      "source": [
        "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification, pipeline # Import the pipeline function\n",
        "\n",
        "# Define the checkpoint name for the zero-shot image classification model\n",
        "checkpoint = \"openai/clip-vit-base-patch32\" # Replace with the desired model checkpoint\n",
        "\n",
        "# Create the zero-shot image classification pipeline\n",
        "detector = pipeline(\"zero-shot-image-classification\", model=checkpoint) # Assign the pipeline to the variable 'detector'\n",
        "\n",
        "model = AutoModelForZeroShotImageClassification.from_pretrained(checkpoint)\n",
        "processor = AutoProcessor.from_pretrained(checkpoint)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5RphpyLY-hPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando mais bibliotecas e carregando a imagem"
      ],
      "metadata": {
        "id": "2rfNFAUtwIpL"
      }
    },
    {
      "source": [
        "url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR2pzAJyx7WdXZpkBpz389qQCAFcX45_G1ccg&s\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "image_array = skimage.io.imread(url)\n",
        "# Create a PIL Image object from the NumPy array\n",
        "im = Image.fromarray(image_array)\n",
        "# Use display to show the image in the notebook\n",
        "display(im)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wnJ_MsGCvYpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazendo as predições por classes"
      ],
      "metadata": {
        "id": "EsH5QM_0xIvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = detector(image, candidate_labels=[\"human being\", \"road\", \"car\", \"motocycle\"])\n",
        "predictions"
      ],
      "metadata": {
        "id": "9VWyTn4kwFb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}